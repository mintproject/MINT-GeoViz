{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# River Explorer Dashboard\n",
    "Modified: Sep 9, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import datetime as dt\n",
    "import numpy as np, scipy as sp, pandas as pd, geopandas as gpd\n",
    "import intake,param\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print \n",
    "\n",
    "import joblib\n",
    "import pdb\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import ipywidgets as iw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True\n",
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "import xarray.ufuncs as xu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "import xarray.ufuncs as xu\n",
    "\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param, Tap, Selection1D, PointerXY, RangeXY\n",
    "from holoviews import streams\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews import tile_sources as gvts\n",
    "\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Add the utils directorys to the search path\n",
    "CURR_UTILS = Path('../utils').absolute()\n",
    "\n",
    "DIRS2ADD = [CURR_UTILS]\n",
    "for UTILS_DIR in DIRS2ADD:\n",
    "    assert UTILS_DIR.exists()\n",
    "    if str(UTILS_DIR) not in sys.path:\n",
    "        sys.path.insert(0, str(UTILS_DIR))\n",
    "        print(f\"Added {str(UTILS_DIR)} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Grab registered bokeh renderer\n",
    "print(\"Currently available renderers: \", *hv.Store.renderers.keys())\n",
    "renderer = hv.renderer('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Path.ls = lambda x: [o.name for o in x.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, Point\n",
    "from geo_helpers import bounds2poly, crop_gdf_to_bounds, get_polys_at_lonlat\n",
    "from utils import nprint, get_mro\n",
    "from river_helpers import load_river_csvs, get_basin_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Set default holoviews style options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%opts Image [colorbar=True, tools=['hover'], active_tools=['wheel_zoom']] Curve [tools=['hover']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "H,W = 1000,1000\n",
    "CURVE_H, CURVE_W = 300, 1000\n",
    "opts.defaults(\n",
    "    \n",
    "    opts.Image(active_tools=['wheel_zoom'], tools=['hover'], colorbar=True),\n",
    "    opts.Curve(active_tools=['wheel_zoom'], tools=['hover'], padding=0.1,\n",
    "              height=CURVE_H, width=CURVE_W),\n",
    "    opts.Scatter(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "    opts.HLine(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "\n",
    "    opts.RGB(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "    opts.Overlay(active_tools=['wheel_zoom']),\n",
    "    \n",
    "    opts.Points(active_tools=['wheel_zoom'], tools=['hover','tap']),\n",
    "    opts.Path(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "\n",
    "    opts.Polygons(active_tools=['wheel_zoom'], tools=['hover','tap']),\n",
    "    opts.WMTS(height=H, width=W),\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Basemap tile\n",
    "We need to handle the projection from latlon to web mercator (which is what the hv.tiles expect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# basemap = gvts.EsriImagery\n",
    "# basemap\n",
    "wmts_url = 'https://maps.wikimedia.org/osm-intl/{Z}/{X}/{Y}@2x.png'\n",
    "\n",
    "# basemap = gv.tile_sources.EsriImagery\n",
    "# basemap = gv.tile_sources.EsriUSATopo\n",
    "# basemap = gv.tile_sources.StamenTerrain\n",
    "topomap = gv.tile_sources.EsriNatGeo\n",
    "labelmap = gv.tile_sources.StamenLabels \n",
    "basemap = topomap #* labelmap\n",
    "\n",
    "# river = gv.feature.rivers\n",
    "# boarders = gv.Feature(cf.BORDERS)\n",
    "# base = basemap * boarders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    " 1. River measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_root = Path.home()/'data/mint'\n",
    "data_dir = data_root/'river'\n",
    "assert data_dir.exists()\n",
    "data = load_river_csvs(data_dir)\n",
    "data['geometry'] = gpd.points_from_xy(data.Longitude, data.Latitude)\n",
    "# Geopadnas river measurement data\n",
    "gdf_data = gpd.GeoDataFrame(data)\n",
    "gdf_data.crs = {'init': 'epsg:4326'}\n",
    "gdf_data.head()\n",
    "\n",
    "bounds = gdf_data.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# nprint(len(data), data.head(), data.sample(10))\n",
    "c = 0\n",
    "for coord, g in data.groupby( ['Latitude', 'Longitude'] ):\n",
    "    if c >= 5:\n",
    "        break\n",
    "    print(coord, len(g))\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gvd = gv.Dataset(data, kdims=['Latitude', 'Longitude', 'Time'], vdims=['River_Width', 'River_Depth'])\n",
    "dmap = gvd.to(gv.Points, kdims=['Longitude', 'Latitude'], vdims=['River_Width', 'River_Depth'], \n",
    "             dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dmap.opts(color='River_Width', size='River_Width', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Get unique points: With Avg. Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "points = []\n",
    "lats, lons = [], []\n",
    "avg_ws = []\n",
    "for (lat,lon), g in data.groupby(['Latitude', 'Longitude']):\n",
    "    points.append(Point(lon, lat))\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    avg_ws.append(g.River_Width.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_avg = pd.DataFrame({'geometry': points,\n",
    "                           'Longitude': lons,\n",
    "                           'Latitude': lats,\n",
    "                           'River_Width_Avg': avg_ws})\n",
    "df_avg.head()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gv_avg = gv.Points(df_avg, \n",
    "                   ['Longitude', 'Latitude'], \n",
    "                   'River_Width_Avg').opts(\n",
    "    color=dim('River_Width_Avg').norm(), \n",
    "    size=dim('River_Width_Avg').norm()*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_gv_avg(scale):\n",
    "    gv_avg = gv.Points(df_avg, \n",
    "                       ['Longitude', 'Latitude'], \n",
    "                       'River_Width_Avg')\n",
    "    return gv_avg.opts(color=dim('River_Width_Avg').norm(), \n",
    "                       size=dim('River_Width_Avg').norm()*scale)\n",
    "\n",
    "# parameterized class as a strem\n",
    "class Scale(param.Parameterized):\n",
    "    scale = param.Number(default=15, bounds=(10,30))\n",
    "    \n",
    "# Add flexibility to set the size of points\n",
    "scale = Scale()\n",
    "scale_stream = streams.Params(scale)\n",
    "dmap_gv_avg = hv.DynamicMap(get_gv_avg, \n",
    "                            streams=[scale_stream])\n",
    "dmap_gv_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "2. Basins data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "basin_dir = data_root/'hybas_world_lev05_v1c'; assert basin_dir.exists()\n",
    "basin_data = gpd.read_file(basin_dir)[['HYBAS_ID', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# check imported geometry's validity\n",
    "len(basin_data)\n",
    "basin_data['valid'] = basin_data.geometry.is_valid\n",
    "bad_basins = basin_data[~basin_data.valid]\n",
    "len(bad_basins)\n",
    "\n",
    "\n",
    "for i in range(len(basin_data)):\n",
    "    try:\n",
    "        \n",
    "    if !basin_data.valid.item():\n",
    "        b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gdf_basins = crop_gdf_to_bounds(basin_data,\n",
    "                                bounds,\n",
    "                                remove_empty=True).reset_index().drop('index', axis=1)\n",
    "gdf_basins['HYBAS_ID']=gdf_basins.HYBAS_ID.astype(str)\n",
    "print(len(gdf_basins))\n",
    "gdf_basins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gv_basins = gv.Polygons(gdf_basins, vdims=['HYBAS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%opts WMTS [height=H, width=W] Polygons(alpha=0.5)\n",
    "basemap * gv_basins * dmap * dmap_gv_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "3. Assign basin_id to points in river measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## GeoPandas from river pandas dataframe\n",
    "bids = []\n",
    "c = 0\n",
    "for lon, lat in zip(data.Longitude, data.Latitude):\n",
    "    bid = get_basin_id(gdf_basins, lon,lat)\n",
    "    bids.append(bid)\n",
    "    if c%30==0: print(lon, lat, bid)\n",
    "    c += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data['HYBAS_ID'] = bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Geopadnas river measurement data\n",
    "gdf_data = gpd.GeoDataFrame(data)\n",
    "gdf_data.crs = {'init': 'epsg:4326'}\n",
    "gdf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Add LatLon Tab selector stream\n",
    "- Fetch the lat/lon of the mouse click position on the basemap\n",
    "\n",
    "    1. Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def select_data_at_lonlat(data, lon, lat):\n",
    "    \"\"\"\n",
    "    data: dataFrame or GeoDataFrame\n",
    "    lat: float\n",
    "    lon: float\n",
    "    \"\"\"\n",
    "    return data[np.isclose(data.Longitude, lon) & np.isclose(data.Latitude, lat)]\n",
    "\n",
    "def tseries_from_lonlat(data, lon, lat):\n",
    "    df = select_data_at_latlon(data, lon, lat)\n",
    "    curve_w = hv.Curve(df, 'Time', 'River_Width', label='width')\n",
    "    curve_d = hv.Curve(df, 'Time', 'River_Depth', label='depth')\n",
    "    return curve_w * curve_d \n",
    "\n",
    "def tseries_from_index(data, \n",
    "                       index_src, \n",
    "                       index):\n",
    "    if len(index) < 1:\n",
    "        return hv.Curve([])\n",
    "    elif len(index) > 1:\n",
    "        print('Warning: multiple points were selected. Only care for the first point')\n",
    "        index = index[:1]\n",
    "              \n",
    "    lon,lat = index_src.iloc[index].Longitude.item(),index_src.iloc[index].Latitude.item()\n",
    "    print(lon, type(lon),lat, type(lat))\n",
    "    df = select_data_at_lonlat(data, lon, lat)\n",
    "    curve_w = hv.Curve(df, 'Time', 'River_Width', label='width')\n",
    "    curve_d = hv.Curve(df, 'Time', 'River_Depth', label='depth')\n",
    "    return curve_w * curve_d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "    2. Register streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# stream_xy = PointerXY(name='lonlat', \n",
    "#                     x=34., y=9., source=gv_basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stream_tab = Selection1D(name='tab', source=gv_avg, index=[0])\n",
    "dmap_tab = hv.DynamicMap(lambda index: hv.Div(f'point index:  {index}'),\n",
    "                        streams=[stream_tab])\n",
    "dmap_tseries = hv.DynamicMap(lambda index: tseries_from_index(data, df_avg, index),\n",
    "                             streams=[stream_tab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stream_btab = Selection1D(name='btap', source=gv_basins, index=[0])\n",
    "debug_btab = hv.DynamicMap(lambda index: hv.Div(f'basin index:  {index}'),\n",
    "                        streams=[stream_btab])\n",
    "gv_basins + debug_btab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "min_val = np.min(data[['River_Width', 'River_Depth']].min().to_list())\n",
    "max_val = np.max(data[['River_Width', 'River_Depth']].max().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#overlay\n",
    "#cmap for points:  plt.cm.gist_earth, plasma, inferno, fire, visidis\n",
    "scale.sacle=40\n",
    "\n",
    "(\n",
    "    basemap \n",
    "    * gv_avg.opts(cmap='plasma') #* dmap_gv_avg \n",
    "#     * gv_basins.opts(alpha=0.1)\n",
    "    + dmap_tseries.opts(\n",
    "     opts.Curve(framewise=True, \n",
    "                show_grid=True, \n",
    "                ylim=(min_val,max_val)\n",
    "               )\n",
    " )\n",
    ").cols(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "OLD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from river_helpers import select_gdf_at_lonlat, get_basin_id\n",
    "\n",
    "def cb_select_basin(gdf, lon, lat, vdim_col='HYBAS_ID'):\n",
    "    gdf_selected = select_gdf_at_lonlat(gdf,lon,lat)\n",
    "    if len(gdf_selected) > 0:\n",
    "        return gv.Polygons(gdf_selected, \n",
    "                           vdims=vdim_col if vdim_col in gdf_selected.columns else None,\n",
    "                           group='Basin')\n",
    "    else:\n",
    "        return gv.Polygons([])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "                        \n",
    "dmap_basin = hv.DynamicMap(lambda x,y: get_basins(gdf_basins, x, y), \n",
    "                           streams=[stream_xy]).opts(color='red', alpha=0.5)\n",
    "\n",
    "dmap_basin_id=hv.DynamicMap(lambda x,y:hv.Div(f'Lng:{ x:.3f}, Lat: {y:.3f}, basin: {get_basin_id(gdf_basins,x,y)}'), \n",
    "                           streams=[stream_xy])\n",
    "\n",
    "dmap_basin #+ dmap_basin_id\n",
    "# )\n",
    "# + \n",
    "# pt_showbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    gv_basins * dmap_basin + dmap_basin_id \n",
    ").opts(\n",
    "    opts.Polygons(alpha=0.5, color='red')\n",
    "    \n",
    ")#+ pt_showbox #hv.DynamicMap(lambda x,y: get_basins(gdf_basins, x, y), streams=[stream_xy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "get_tseries(gdf_basins, gdf_data,  '1050040270')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gv.Points(gdf_data.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def select_data_at_time(data, t):\n",
    "    \"\"\"\n",
    "    data: dataFrame like object\n",
    "    tlist: Iterable of dt.datetime object or pd.Timestamp object\n",
    "        - eg: t = [dt.datetime(2016,1,9)]\n",
    "    \"\"\"\n",
    "#     return data[data.Time == t]\n",
    "    df = data[data.Time == t]\n",
    "    points = gv.Points(df, \n",
    "                     kdims=['Longitude', 'Latitude'], \n",
    "                     vdims=['River_Width', 'River_Depth'])\n",
    "    return points.opts(color='River_Width', size=dim('River_Depth')*3)\n",
    "\n",
    "def select_data_at_times(data, tlist):\n",
    "    \"\"\"\n",
    "    data: dataFrame like object\n",
    "    tlist: Iterable of dt.datetime object or pd.Timestamp object\n",
    "        - eg: t = [dt.datetime(2016,1,9)]\n",
    "    \"\"\"\n",
    "    return data[data.Time.isin(tlist)]\n",
    "\n",
    "\n",
    "def test_select_data_at_times():\n",
    "    times = data.Time.to_list()\n",
    "    displat(select_data_at_times(data, times[:2]).head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dmap = hv.DynamicMap(lambda t: select_data_at_time(data, t), \n",
    "                     kdims='t').redim.values(t=times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(base * gv_basins * dmap).opts(\n",
    "    opts.Points(color='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tmin, tmax = data.Time.min(), data.Time.max()\n",
    "\n",
    "class RiverViz(param.Parameterized):\n",
    "    time = param.Date(tmin, bounds=(tmin, tmax))\n",
    "    basin = param.ObjectSelector(default="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- [] use width as size\n",
    "- time series: river width and depth in y-axis\n",
    "\n",
    "---\n",
    "\n",
    "- basin vector: use clicks on it and show basin id\n",
    "    -> put into basin \n",
    "    -> filter by bounds\n",
    "- show all data (interpolated)\n",
    "    -> use select by date range\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ts = times[:2]\n",
    "data[data.Time.isin(ts)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "t1 = dt.datetime(2016,1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "t1 == _157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data[data.Time == t1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Ethiopia spatial data\n",
    "https://www.diva-gis.org/gdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# ethiopia bbox\n",
    "bounds = 32.95418, 3.42206, 47.78942, 14.95943 #minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "road_dir = data_root/'ETH_rds'\n",
    "wat_dir = data_root/'ETH_wat'\n",
    "hflow_dir = data_root/'h1k_flow'\n",
    "basin_dir = data_root/'hybas_world_lev05_v1c'\n",
    "\n",
    "road_dir.exists(), wat_dir.exists(), hflow_dir.exists(), basin_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gdf_rds = crop_gdf_to_bounds(gpd.read_file(road_dir)[['geometry']],\n",
    "                             bounds,\n",
    "                             remove_empty=True).reset_index().drop('index', axis=1)\n",
    "\n",
    "gdf_wats = crop_gdf_to_bounds(gpd.read_file(wat_dir)[['NAME', 'geometry']],\n",
    "                              bounds,\n",
    "                              remove_empty=True).reset_index().drop('index', axis=1)\n",
    "\n",
    "gdf_hflow = crop_gdf_to_bounds(gpd.read_file(hflow_dir),\n",
    "                               bounds, \n",
    "                               remove_empty=True).reset_index().drop('index', axis=1)\n",
    "\n",
    "gv_rds = gv.Path(gdf_rds, label='roads') \n",
    "gv_wats = gv.Polygons(gdf_wats, label='water')\n",
    "gv_hflow = gv.Path(gdf_hflow, label='hflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(gdf_rds.geom_type.unique(), gdf_wats.geom_type.unique(), gdf_hflow.geom_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "len(gdf_rds), len(gdf_wats), len(gdf_hflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Southern Africa Dataset\n",
    "fpath_sa = '/home/hayley/data/mint/FLDAS/FLDAS_NOAH01_A_SA_D.001/2019/04/FLDAS_NOAH01_A_SA_D.A201904*.001.nc'\n",
    "fpath_ea = '/home/hayley/data/mint/FLDAS/FLDAS_NOAH01_A_EA_D.001/2019/04/FLDAS_NOAH01_A_EA_D.A201904*.001.nc'\n",
    "ds_sa = xr.open_mfdataset(fpath_sa)\n",
    "ds_sa = ds_sa.drop_dims('bnds')\n",
    "\n",
    "ds_ea = xr.open_mfdataset(fpath_ea)\n",
    "ds_ea = ds_ea.drop_dims('bnds')\n",
    "\n",
    "         \n",
    "# print(ds_ea)\n",
    "# print(ds_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "xrd_ea = ds_ea.persist()\n",
    "xrd_sa = ds_sa.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# data variable list\n",
    "varnames_ea = list(ds_ea.data_vars.keys())\n",
    "varnames_sa = list(ds_sa.data_vars.keys())\n",
    "varnames = varnames_ea\n",
    "varname = varnames[3]\n",
    "print(varname)\n",
    "\n",
    "#set height, width for images (for plotting)\n",
    "H_IMG, W_IMG = 400, 400\n",
    "\n",
    "# create holoviews dataset containers \n",
    "kdims = ['X','Y','time']\n",
    "hvd_ea = hv.Dataset(xrd_ea, kdims)\n",
    "hvd_sa = hv.Dataset(xrd_sa, kdims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# colormaps\n",
    "## discretize it conveniently using holoview's \"color_level\" option\n",
    "t_fixed = '2019-04-05'\n",
    "varname = varnames[5] \n",
    "print(\"Selecting a datavariable at a fixed time point: \", t_fixed, varname)\n",
    "\n",
    "# timg_ea = hvd_ea.select(time=t_fixed).to(gv.Image, kdims=['X', 'Y'], vdims=varname) #this returns a holomap, not a hv.Image object\n",
    "# To construct an hv.Image object, we need to pass in the xr.DataArray (ie. one value variable)\n",
    "print(xrd_ea[varname].isel(time=3) )\n",
    "timg_ea = gv.Image(xrd_ea[varname].isel(time=3) , ['X','Y'], crs=ccrs.PlateCarree()) #Opt: vdims=varname\n",
    "timg_sa = gv.Image(xrd_sa[varname].isel(time=3) , ['X','Y'], crs=ccrs.PlateCarree()) #Opt: vdims=varname\n",
    "# print(timg_sa)\n",
    "# gv.tile_sources.Wikipedia * timg_ea.opts(alpha=0.5,width=W_IMG, height=H_IMG) #+ timg_sa.opts(width=W_IMG, height=H_IMG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Add LatLon Tab selector stream\n",
    " Modified: Jun 16, 2019\n",
    "\n",
    "- Fetch the lat,lon location from the mouse location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from holoviews.streams import Tap, Selection1D, PointerXY, RangeXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# point_src = timg_ea\n",
    "# pointxy = PointerXY(name='pt_latlon', \n",
    "#                     x=0., y=0.,source=point_src)\n",
    "# pointxy.print_param_values()\n",
    "# selection = Selection1D(source=timg_ea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Modified: Jun 17, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# tseries_opts = {\n",
    "    \n",
    "def cb_tseries(xrd, varname, x, y, method='nearest'):\n",
    "    tseries = xrd[varname].sel(X=x, Y=y,method=method)\n",
    "    tseries_label = f\"Time Series at Lon,Lat = ({x:.2f},{y:.2f}) \"\n",
    "    scatter = hv.Scatter(tseries)\n",
    "    curve = hv.Curve(tseries)\n",
    "\n",
    "    mean = hvu.extract_item(tseries.mean())\n",
    "    mean_line = hv.HLine(mean, label='tseries_mean')\n",
    "    t_midpoint = pd.Timestamp(hvu.extract_item(tseries.coords['time'][len(tseries)//2]))\n",
    "    mean_label = hv.Labels([(t_midpoint, mean, f'mean: {mean:.3f}')])\n",
    "    layout = (\n",
    "        curve.opts(alpha=0.5, line_width=1) \n",
    "        * scatter.opts(width=W, padding=0.2, size=5) \n",
    "        * mean_line.opts(color='black', alpha=0.5, line_width=1) \n",
    "        * mean_label.opts(text_font_size='8pt',text_alpha=0.5)\n",
    "    )\n",
    "    layout.label=tseries_label\n",
    "    return layout\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Add another callback. \n",
    "Modified: Jun 17, 2019\n",
    "\n",
    "- On LatLon selection, compute the statistics of the current `varname` at `latlon_selected` across time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def cb_tstats(xrd, varname, x, y, \n",
    "              method='nearest',\n",
    "             show_as_timestamp=True,\n",
    "             decimals=3):\n",
    "    tseries = xrd[varname].sel(X=x, Y=y,method=method)\n",
    "    df = hvu.get_stats(tseries, \n",
    "                       show_as_timestamp=show_as_timestamp,\n",
    "                       decimals=decimals)\n",
    "    \n",
    "    # Add metadata on selected latlon point\n",
    "#     df['point_idx'] = index[0]#\n",
    "    df['lat'] = y\n",
    "    df['lon'] = x\n",
    "    \n",
    "    cols = df.columns.to_list()\n",
    "    cols = cols[-2:] + cols[:-2]\n",
    "    df = df[cols]\n",
    "    label = f\"Time Series Stats at Lon,Lat = ({x:.2f},{y:.2f}) \"\n",
    "    return hv.Table(df, label=label)\n",
    "################################################################################\n",
    "    # Cleanup for table's aesthetics\n",
    "    # Coerce object type to datetime objs\n",
    "#     df = df.T\n",
    "#     if show_as_timestamp:\n",
    "#         df.loc['argmin'] = pd.Timestamp(df.loc['argmin'])\n",
    "#         pdb.set_trace()\n",
    "#         display(df.loc['argmin'])\n",
    "\n",
    "#         df.loc['argmax'] = pd.to_datetime(df.loc['argmax'])\n",
    "#     df = df.reset_index()\n",
    "\n",
    "#     return hv.Table(df.values, 'stat', 'value')\n",
    "################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cb_tstats(xrd_ea, varname, 40,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "curve_opts = {'framewise':True}\n",
    "varname = varnames[1]\n",
    "# timg_ea +\\\n",
    "# hv.DynamicMap(lambda x,y: get_tseries(xrd_ea, varname, x, y,curve_opts=curve_opts),\n",
    "#               streams=[pointxy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Combine the two callbacks for LatLon Tab selector\n",
    "Modified: Jun 17, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def cb_latlon_tab(xrd, varname, x, y, **kwargs):\n",
    "    \"\"\"\n",
    "    Creates a hv.Overlay object with two elements\n",
    "    - layout = tseries + table\n",
    "    where \n",
    "        - tseries: itself an overlay with scatter, curve, hline and a text for \n",
    "        the time series data at the selected LonLat location\n",
    "        - table: contains basic statistics of the time series data at the selected location\n",
    "    Args:\n",
    "    - xrd (xarray.Dataset)\n",
    "    - varname (str)\n",
    "    - x (int): index to xrd's 'X' dim\n",
    "    - y (int): index to xrd's 'Y' dim\n",
    "    \n",
    "    kwargs:\n",
    "    - method (str): xarray's .sel method. Default: 'nearest'\n",
    "    - show_as_teimstamp (bool): if True, the table will show time data as time rather than an index\n",
    "    - decimals (int): number of decimals to kwarg to np.around() for float point display\n",
    "    \n",
    "    Returns\n",
    "    - layout (hv.Overlay)\n",
    "    \"\"\"\n",
    "    # Get the kwarg values\n",
    "    method = kwargs.get('method', 'nearest')\n",
    "    show_as_timestamp = kwargs.get('show_as_timestamp', True)\n",
    "    decimals = kwargs.get('decimals', 3)\n",
    "    \n",
    "    # Get hv elements\n",
    "    tseries = cb_tseries(xrd, varname, x, y, method=method)\n",
    "    tstats = cb_tstats(xrd, varname, x, y, \n",
    "                       method=method, show_as_timestamp=show_as_timestamp, decimals=decimals)\n",
    "    # todo:\n",
    "    # - add the selection1d stream on the scatter plot\n",
    "#     tseries_selection = Selection1D...\n",
    "    \n",
    "    return (tseries + tstats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# cb_latlon_tab(xrd_ea, varname, 40,10)\n",
    "dmap_latlon_tab = hv.DynamicMap(\n",
    "    lambda x,y, **kwargs: cb_latlon_tab(xrd_ea, varname, x,y, **kwargs),\n",
    "    streams=[tap_latlon]\n",
    ")\n",
    "layout = timg_ea + dmap_latlon_tab.collate()\n",
    "layout.opts(\n",
    "    opts.Image(**img_opts),\n",
    "    opts.Curve(**curve_opts),\n",
    "    opts.Table(**tbl_opts)\n",
    "    \n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Add a Selection1D stream to the time-series scatter plot\n",
    "- Upon click, show the image (of the value of the current variable at the current latlon) at that time point selected by this Selection1D stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tseries = cb_tseries(xrd_ea, varname, 40, 10, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import Output\n",
    "out = Output()\n",
    "\n",
    "@out.capture(clear_output=True)\n",
    "def listener(*args, **kwargs):\n",
    "    print('Scatter selector listener called')\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "\n",
    "tscatter_selection = Selection1D(source=tseries.Scatter.I)\n",
    "tscatter_selection.add_subscriber(listener)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_img(xrd, varname, tidx):\n",
    "    \"\"\"\n",
    "    Returns a hv.Image of xarray dataset's variable named `varname` at `tidx`th time\n",
    "    Args:\n",
    "    - xrd (xarray dataset)\n",
    "    - varname (str)\n",
    "    - tidx (int)\n",
    "    Returns:\n",
    "    - img (hv.Image)\n",
    "    \"\"\"\n",
    "    return gv.Image(xrd[varname].isel(time=tidx), ['X','Y'], varname)\n",
    "# get_img(xrd_ea, varname, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%opts Scatter [tools=['tap']] {+framewise}\n",
    "@out.capture(clear_output=True)\n",
    "def cb_tscatter(xrd, varname, index):\n",
    "    print('cb_tscatter called. Selected indices: ', index)\n",
    "    if not index:\n",
    "        index = [0] #todo: current tindex\n",
    "    tidx = index[0]\n",
    "    return get_img(xrd, varname, tidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dmap_tselection = hv.DynamicMap(\n",
    "    lambda index: cb_tscatter(xrd_ea, varname, index),\n",
    "    streams=[tscatter_selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(tseries + (basemap*dmap_tselection)).cols(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tscatter_selection.event(index=[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tscatter_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Add RangeXY linked stream\n",
    "Modified: Jun 16, 2019\n",
    "\n",
    "- Fetch the x and y ranges of the current view\n",
    "    - Fetch appropriate vector tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "range_src = timg_ea\n",
    "x_range, y_range = hvu.lbrt2ranges(range_src.bounds.lbrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rangexy = RangeXY(x_range = x_range,\n",
    "                  y_range = y_range,\n",
    "                  source=timg_ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# rangexy.print_param_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def cb_rangexy(x_range, y_range):\n",
    "    lbrt = hvu.ranges2lbrt(x_range, y_range)\n",
    "    print(f'x_range: {x_range}')\n",
    "    print(f'y_range: {y_range}')\n",
    "    print(f'lbrt: ', lbrt)\n",
    "    \n",
    "    df = pd.DataFrame( [lbrt], columns='min_x min_y max_x max_y'.split() )\n",
    "    return hv.Table( df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# (\n",
    "#     timg_ea + \\\n",
    "#     hv.DynamicMap(cb_rangexy, streams=[rangexy])\n",
    "# ).cols(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Add regional statistics computation\n",
    "Modified: Jun 16, 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Putting the streams together\n",
    "Modified: Jun 16, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Set style opts\n",
    "curve_opts = {'framewise':True}\n",
    "img_opts = dict(width=W, height=H,\n",
    "                axiswise=True, framewise=False,\n",
    "               tools=['hover'],\n",
    "               active_tools=['wheel_zoom'])\n",
    "tbl_opts = dict(width = W)\n",
    "varname = varnames[1]\n",
    "\n",
    "# Define streams\n",
    "## Tab stream and  dmap\n",
    "tap_latlon = Tap(name='tap_latlon', x = 0.0, y=0.0, source=timg_ea)\n",
    "dmap_latlon_tab = hv.DynamicMap(\n",
    "    lambda x,y, **kwargs: cb_latlon_tab(xrd_ea, varname, x,y, **kwargs),\n",
    "    streams=[tap_latlon]\n",
    ")\n",
    "\n",
    "## Range stream and dmap\n",
    "range_src = timg_ea\n",
    "x_range, y_range = hvu.lbrt2ranges(range_src.bounds.lbrt())\n",
    "rangexy = RangeXY(x_range = x_range,\n",
    "                  y_range = y_range,\n",
    "                  source=timg_ea)\n",
    "dmap_range_tbl = hv.DynamicMap(cb_rangexy, streams=[rangexy])\n",
    "\n",
    "## Putting all together\n",
    "layout = timg_ea + dmap_latlon_tab.collate()\n",
    "layout.opts(\n",
    "    opts.Image(**img_opts),\n",
    "    opts.Curve(**curve_opts),\n",
    "    opts.Table(**tbl_opts) \n",
    ").cols(1)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "timg_ea + dmap_tseries + dmap_tstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "---\n",
    "## Panel Dashboards\n",
    "Modified: Jun 10, 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# import param\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "# from holoviews.streams import Params\n",
    "from geoviews.tile_sources import EsriImagery\n",
    "from colorcet import palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#dataset: hvd_ea, hvd_sa\n",
    "xr_datasets = {\n",
    "    'EA': xrd_ea,\n",
    "    'SA': xrd_sa\n",
    "}\n",
    "\n",
    "hv_datasets = {\n",
    "    'EA': hvd_ea,\n",
    "    'SA': hvd_sa\n",
    "}\n",
    "april = pd.date_range('2019-04-01', periods=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# create dmap \n",
    "xrd_ea_small = xrd_ea.isel(time=[3,4])\n",
    "xrd_sa_small = xrd_sa.isel(time=[3,4])\n",
    "\n",
    "## Wrong: this creates holomaps\n",
    "# dmap_ea_small = hv.Dataset(xrd_ea_small, kdims).to(hv.Image, ['X','Y'], varname, label='EA')\n",
    "# dmap_sa_small = hv.Dataset(xrd_sa_small, kdims).to(hv.Image, ['X','Y'], varname, label='SA')\n",
    "\n",
    "# datashade opts\n",
    "from colorcet import fire\n",
    "dopts = dict(width=W, height=H,\n",
    "#             x_sampling=0.5, \n",
    "#             y_sampling=0.5,\n",
    "            )\n",
    "\n",
    "img_opts = dict(width=W, height=H,\n",
    "                axiswise=True, framewise=False,\n",
    "               tools=['hover'],\n",
    "               active_tools=['wheel_zoom'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## FLDASExplorer with panel\n",
    "Modified: Jun 13, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "class FLDASExplorer(param.Parameterized):\n",
    "    region = param.ObjectSelector(default='EA', objects=['EA', 'SA'])\n",
    "    varname = param.ObjectSelector(default=varnames[0],objects=varnames)\n",
    "    time = param.Date(dt.datetime(2019,4,1), bounds=(dt.datetime(2019, 4, 1), dt.datetime(2019, 4, 30)))\n",
    "    alpha = param.Number(default=1.0, bounds=(0.0,1.0))\n",
    "#     cmap = param.ObjectSelector(default='fire', objects=['fire'])\n",
    "\n",
    "                                                    \n",
    "    @param.depends('region', 'varname', 'time')#, 'alpha')#, 'cmap')\n",
    "    def view(self):\n",
    "        xrd = xrd_ea if self.region == 'EA' else xrd_sa\n",
    "        img = gv.Image(xrd.sel(time=self.time)[self.varname], ['X','Y'], crs=ccrs.PlateCarree())    \n",
    "        \n",
    "    #     datashade returns a hv.DynamicMap which dynamically re-renders this img as we zoom/pan\n",
    "        return basemap*datashade(img.opts(**img_opts), \n",
    "                                 cmap=fire,#self.cmap, \n",
    "#                                  alpha=self.alpha,\n",
    "                                 **dopts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "explorer = FLDASExplorer()\n",
    "# img_dmap = hv.DynamicMap(explorer.view)\n",
    "app = pn.Row( explorer.param, explorer.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "app.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "todo: \n",
    "    - add a time slider and link it to the time input box widget\n",
    "    - handle projection better (for the basemap and the latlon- data)\n",
    "    - change panel pane's width and height for the image layout\n",
    "    - geo statistics overlay using raster(...) and datashader operations\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml]",
   "language": "python",
   "name": "conda-env-earthml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
