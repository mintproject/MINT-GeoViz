{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import intake\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print \n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "from holoviews import opts\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def check_url(path):\n",
    "    r = requests.head(path)\n",
    "    return r.status_code == requests.codes.ok\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Let's download some examples files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/data_url.jpg\" alt=\"mint-data-fs\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The acronyms can be searched on NASA'S Open Data [Catalog](https://data.nasa.gov/browse)\n",
    "* NASA's EARTHDATA GES DISC hosts this data [here](https://is.gd/a6wP0x)\n",
    "\n",
    "* Summary:\n",
    "    - FLDAS: FLDAS(Famine Early Warning Systems Network - FEWS NET) Land Data Assimilation System\n",
    "    - NOAH, VIC: simulation models \n",
    "        - '01', '025': model versions\n",
    "    - A: Anomaly, C: Climatoloty: what the models are about\n",
    "    - EA: (aoi) Eastern Africa\n",
    "    - D or M: (time period) 'Daily' or 'Monthly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# HALT!\n",
    "Modified: May 27, 2019\n",
    "- Submitted an [issue](https://is.gd/1Iytqf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenDAP authroization\n",
    "from netrc import netrc\n",
    "username, _, pw = netrc().hosts['urs.earthdata.nasa.gov']\n",
    "\n",
    "#OPENDAP client\n",
    "from pydap.client import open_url\n",
    "from pydap.cas.urs import setup_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLDAS_BASE_URL = 'https://hydro1.gesdisc.eosdis.nasa.gov/opendap/hyrax/FLDAS/'\n",
    "# resource = 'FLDAS_NOAH01_C_SA_MA.001/2013/FLDAS_NOAH01_C_SA_MA.ANOM201301.001.nc'\n",
    "models = ['NOAH01', 'VIC025']\n",
    "aois = ['EA','SA','WA']    \n",
    "\n",
    "year = 2019\n",
    "month = 4\n",
    "day = 1\n",
    "model = models[0]\n",
    "aoi = aois[0]\n",
    "resource = f'FLDAS_{model}_A_{aoi}_D.001/{year}/{month:02}/FLDAS_{model}_A_{aoi}_D.A{year}{month:02}{day:02}.001.nc'\n",
    "print(resource)\n",
    "\n",
    "resource_spec = {\n",
    "    'model':model,\n",
    "    'aoi': aoi,\n",
    "    'year':year,\n",
    "    'month':month,\n",
    "    'day':day\n",
    "}\n",
    "pprint(resource_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resource_spec(model, aoi, year, month, day):\n",
    "    \"\"\"\n",
    "    - model (str): one of ['NOAH01', 'VIC025']\n",
    "    - aoi (str): one of ['EA','SA','WA'] \n",
    "    - year (int): 4 digit year \n",
    "    - month (int): 1 or 2 digits month\n",
    "    - day (int): 1 or 2 digits day\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'model':model,\n",
    "        'aoi': aoi,\n",
    "        'year':year,\n",
    "        'month':month,\n",
    "        'day':day\n",
    "        }\n",
    "def test_build_resource_spec():\n",
    "    year = 2019\n",
    "    month = 4\n",
    "    day = 1\n",
    "    model = models[0]\n",
    "    aoi = aois[0]\n",
    "    print(build_resource_spec(model, aoi, year, month, day))\n",
    "test_build_resource_spec()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resource = f'FLDAS_{model}_A_{aoi}_D.001/{year}/{month:02}/FLDAS_{model}_A_{aoi}_D.A{year}{month:02}{day:02}.001.nc'\n",
    "# print(resource)\n",
    "    \n",
    "# def build_resource_path(model, aoi, year, month, day):\n",
    "def build_resource_path(**spec):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - spec (dict) which must contain all of the following as key:value\n",
    "        - model (str): one of ['NOAH01', 'VIC025']\n",
    "        - aoi (str): one of ['EA','SA','WA'] \n",
    "        - year (int): 4 digit year \n",
    "        - month (int): 1 or 2 digits month\n",
    "        - day (int): 1 or 2 digits day\n",
    "    Returns:\n",
    "    - resource (str): FLDAS Daily (Abnormality?) Dataset resource path\n",
    "    \"\"\"\n",
    "    path = f'FLDAS_{model}_A_{aoi}_D.001/{year}/{month:02}/FLDAS_{model}_A_{aoi}_D.A{year}{month:02}{day:02}.001.nc'\n",
    "    return path\n",
    "def test_brp():\n",
    "    spec = resource_spec\n",
    "    print(build_resource_path(**spec))\n",
    "test_brp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def get_url(spec, base_url=FLDAS_BASE_URL):\n",
    "    resource_path = build_resource_path(**spec)\n",
    "    return os.path.join(base_url, resource_path)\n",
    "def test_get_url():\n",
    "    spec = resource_spec\n",
    "    url = get_url(spec)\n",
    "    print(get_url(spec))\n",
    "\n",
    "test_get_url()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# url = ('https://hydro1.gesdisc.eosdis.nasa.gov/opendap/hyrax/FLDAS/'\n",
    "#        'FLDAS_NOAH01_A_EA_D.001/2019/04/FLDAS_NOAH01_A_EA_D.A20190401.001.nc')\n",
    "session = setup_session(username, pw, check_url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use xarray.open_dataset with pydap.cas.urs's session object\n",
    "- http://xarray.pydata.org/en/stable/io.html#opendap\n",
    "- PydapDataStore [src](https://is.gd/Wkz1ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "store = xr.backends.PydapDataStore.open(url, session=session)\n",
    "# ds = xr.open_dataset(store) # currently not working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_info = store.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vars_info.keys()) #KeysView object\n",
    "varname = 'SoilMoi00_10cm_tavg'\n",
    "var = store.get(varname) # xr.Variable\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommneded to work with xr.DataArray or xr.DataSet\n",
    "var = xr.DataArray(var)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HALT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to using the local files....\n",
    "Modified: May 27, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read local netcdf files\n",
    "## This works smoothly....\n",
    "for m in np.arange(1,13)[:1]:\n",
    "    fpath = Path(f'/home/hayley/data/FLDAS_NOAH01_A_EA_D.A201904{day:02}.001.nc')\n",
    "    day_ds = xr.open_dataset(fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = day_ds.load()\n",
    "nodata = data.attrs.get('missing_value', None)\n",
    "crs = data.attrs.get('MAP_PROJECTION',None)\n",
    "\n",
    "print(nodata)\n",
    "print(crs) # epsg 4082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go holoviews\n",
    "hv_dataset = hv.Dataset(data)\n",
    "hv_dataset.to(hv.Image, kdims=['time','Y','X'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southern Africa Dataset\n",
    "ds_sa = xr.open_mfdataset('/home/hayley/data/mint/FLDAS_NOAH01_A_SA_D.001/FLDAS_NOAH01_A_SA_D.*.nc4')\n",
    "ds_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eastern Africa Dataset\n",
    "ds_ea = xr.open_mfdataset('/home/hayley/data/mint/FLDAS_NOAH01_A_EA_D.001/2017/08/*.nc')\n",
    "print(ds_ea)\n",
    "varnames = list(ds.variables.keys())\n",
    "nprint('variables: ', varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = ds.sel(bnds=0)\n",
    "ds2 = ds.sel(bnds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "august_data = ds.drop_dims('bnds').load()\n",
    "august_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil = ds.SoilMoi00_10cm_tavg\n",
    "p = soil.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_soil_ds = hv.Dataset(soil) # this will result in right mapping!\n",
    "nprint('soil', soil.dims, soil)\n",
    "nprint('hv_soil_ds', hv_soil_ds)\n",
    "nprint('hv_soil_ds dims',hv_soil_ds.dimensions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv_soil_ds = hv.Dataset(soil, kdims=['time', 'Y', 'X']) # this will result in wrong mapping!\n",
    "# nprint('hv_soil_ds dims',hv_soil_ds.dimensions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv_soil_ds = hv.Dataset(soil, kdims=['X', 'Y', 'time']) # this will result in wrong mapping!\n",
    "# nprint('hv_soil_ds dims',hv_soil_ds.dimensions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax= plt.subplots()\n",
    "\n",
    "pt_lon, pt_lat = (20, 50)\n",
    "soil_pt = soil.sel(X=pt_lon, Y=pt_lat, method='nearest')\n",
    "soil_pt.plot(ax=ax, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_yr_mean = soil.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(soil_pt - soil_yr_mean.sel(X=pt_lon, Y=pt_lat, method='nearest')).plot(ax=ax, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil - soil_yr_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's go holoviews\n",
    "Using full 31 day's (august, 2019) dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%opts Image [tools=['hover']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_dataset = hv.Dataset(ds)\n",
    "print(hv_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_vars = ['X','Y','time', 'time_bnds']\n",
    "for ele in not_vars:\n",
    "    try:\n",
    "        varnames.remove(ele)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "print(varnames)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of variable names\n",
    "\n",
    "# hv.Table({'varname': varnames})\n",
    "t1 = hv.Table({'x': [1,2,3], 'y':[10,20,30]})\n",
    "\n",
    "df = pd.DataFrame({'x': [1,2,3], 'y':[10,20,30]})\n",
    "t2 = hv.Table(df)\n",
    "\n",
    "t3 = hv.Table( ([1,2,3], [10,20,30]), 'col1', 'col2' )\n",
    "\n",
    "t4 = hv.Table( [ (1,10), (2,20), (3,30), (4,40) ], 'col1', 'col2')\n",
    "\n",
    "(t1 + t2 + t3 + t4).cols(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 + t2 + t3 + t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgmap(varname):\n",
    "    print(varname)\n",
    "    varmap = gv.Dataset(ds[varname]).to(gv.Image, kdims=['X','Y']) #dynamic=True to make it dynamicmap\n",
    "    varmap.label = varname\n",
    "    return varmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map0 = get_imgmap(varnames[0])\n",
    "print(map0.name)\n",
    "print(map0.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = get_imgmap(varnames[1])\n",
    "print(map1.name, varmap1.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=500, height=500]\n",
    "layout = (map0 + map1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## holomaps for august fldas data\n",
    "Modified: May 30, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "august_fldas = august_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(august_fldas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'SoilTemp00_10cm_tavg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "august_fldas[varname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_temp_var = august_fldas['SoilTemp00_10cm_tavg']\n",
    "hv_dataset = hv.Dataset(soil_temp_var,kdims = ['dim0', 'dim1', 'time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "august_fldas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_pt(ds, long, lat):\n",
    "    ds_pt = ds.sel(X=long, Y=lat, method='nearest')\n",
    "    return ds_pt\n",
    "    \n",
    "\n",
    "august_longlat = ds_pt(august_data, pt_lon, pt_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt_curve(ds_pt, varname):\n",
    "    hv_dataset = hv.Dataset(ds_pt[varname]) #kdim = time, vdim = varname\n",
    "    return hv_dataset.to(hv.Curve,'time', varname)\n",
    "\n",
    "gen_curve0 = lambda pt_lon, pt_lat: get_pt_curve(ds_pt(august_data, pt_lon, pt_lat), varnames[0])\n",
    "gen_curve0(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_curve1 = lambda pt_lon, pt_lat: get_pt_curve(ds_pt(august_data, pt_lon, pt_lat), varnames[1])\n",
    "gen_curve1(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variablename table\n",
    "len(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ds.variables.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Xarray Workbook 1\n",
    "Modified: May 28, 2019\n",
    "\n",
    "This is my sketchpad to understand xr.DataArray and xr.Dataset constructors.\n",
    "\n",
    "Keys:\n",
    "    - `xarray`'s main motivation is to model after `netcdf` format\n",
    "    - it handles pandas's limitation on 2D (or 3D at max) dataframe\n",
    "    - it maintains the `pandas`'s named dimensions idea\n",
    "    - we can think of it as a multidimensional array(`numpy.ndarray`) with named dimensions\n",
    "    - each dimension has a `name` and `tick-marks`. These tick-marks are called `coordinates`. `numpy` doesn't have this feature, so all of its indexing is by integer/order based. In `xarray`, since we have a name for each dimension (ie. axis) as well as a list of coordinates (ie. tick-marks) for each dimension (again, ie. axis), we can refer to a value in the xrray DataArray container with more semantic-aware indexing\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/xarray_overview_.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(np.matrix('0, 10; 1, 11; 2, 12'))\n",
    "nprint(arr.shape, arr)\n",
    "# np.c_[df, ['a','b','c']] #have you tried this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest DataArray Constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarr = xr.DataArray(arr)\n",
    "print(xarr)\n",
    "\n",
    "# 1. more meaning ful dimension name\n",
    "renamed = xarr.rename(dim_0='date', dim_1='station_id')\n",
    "nprint('renamed', renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `xarray` and `numpy` follow the same dimention assignment order. Dim0 is along the rows, Dim1 is along the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assign some coordinates\n",
    "coords = {\n",
    "    'date': ['2019-01-01', '2019-01-02', '2019-01-03'],\n",
    "    'station_id': ['LA', 'SF']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xarr = renamed.assign_coords(**coords)\n",
    "print(new_xarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can store any relevant metadata as 'attrs'\n",
    "new_xarr.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xarr.attrs.update(unit='km')\n",
    "new_xarr.attrs.update(description='US State Daily Temperature Flux')\n",
    "new_xarr.attrs.update(collector='NASA')\n",
    "new_xarr.attrs.update(last_updated='2019-05-28')\n",
    "new_xarr.attrs.update(license='MIT')\n",
    "\n",
    "\n",
    "pprint(new_xarr.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's specify these parameters at the construction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = new_xarr.attrs.copy()\n",
    "nprint('meta data', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarr2 = xr.DataArray(arr, \n",
    "                     dims = ['time', 'state'],\n",
    "                     # coords as a list of tuples: each tuple = (dimname, coord_values)\n",
    "                     # this results in setting coordinate name same as its dimension's name\n",
    "                     # To set coord's name specifically, use a dictionary format\n",
    "                     #   eg: coords = {coord_name1: coord_vals1, coord_name2, coord_vals2}\n",
    "                     #   In this case, dimensions must be provided explicitly\n",
    "                     #   See example below\n",
    "                     coords=[('time', pd.date_range('2019-01-01', periods=3)),\n",
    "                             ('state', ['LA', 'SF'])],\n",
    "                     attrs=meta,\n",
    "                     name='US state example data array'\n",
    "                    )\n",
    "print(xarr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Dimensions` and their `coordinates` \n",
    "DataArray Constructor\n",
    "```\n",
    "darr = xr.DataArray(\n",
    "        data,\n",
    "        dims=['dimname0', 'dimname1'],\n",
    "        coords=\n",
    "        attrs=\n",
    "        name=\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates\n",
    "1. A dictionary of form {'coordname': coord1, 'coordname2': coords2, ...}  \n",
    "    - This requires the `dims` to be explicitly provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {'coord1': pd.date_range('2019-05-05', periods=3),\n",
    "          'coord2': ['LA','SF']\n",
    "         }\n",
    "darr = xr.DataArray(arr, \n",
    "             dims=['time', 'state'], # this will error because they `dims` must be a subset of `coords.keys()`\n",
    "                    # when `coords` is given as a dictionary. Now I see why `coords` keyword is specified before \n",
    "                    # `dims`\n",
    "             coords=coords,\n",
    "            )\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix the dimension names so that it works.\n",
    "darr = xr.DataArray(arr,\n",
    "                    coords=coords,\n",
    "                    dims=['coord1', 'coord2'])\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of using dictionary format for the `coords` is that we can specify extra coordinates that are about the dimensions (ie. axes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = xr.DataArray(arr, \n",
    "             dims=['time', 'state'],\n",
    "             coords={\n",
    "                 'time': pd.date_range('2019-05-05', periods=3),\n",
    "                 'state': ['LA', 'SF'],\n",
    "                 'const': 17 # more on this extra (dimension-independent) coordinate later\n",
    "             }\n",
    "            )\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But those dimension-independent coordinates have constraints: \n",
    "- a coordinate must have a value of a non-iterable datatype (eg. 15, 0.01, etc but not [1,2,3]). \n",
    "    - It can have a name not in `dims`\n",
    "- If a coordinate's value is an iterable, it's \n",
    "- If a coordinate can have a name that is not in `dims`, but its value must be a tuple (or other iterable) following the tuple constructor format for a coordinate that has a cooresponding dimension. \n",
    "    - Eg: coord3 = ('extra_coordname', ('dimname0', [1,2,3]))\n",
    "\n",
    "Their usecases will be explained in more details later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is okay\n",
    "darr = xr.DataArray(arr, \n",
    "             dims=['time', 'state'],\n",
    "             coords={\n",
    "                 'time': pd.date_range('2019-05-05', periods=3),\n",
    "                 'state': ['LA', 'SF'],\n",
    "                 'coord3': 'hihi' # try any other non-iterable datatypes: 0.01,'a', 'hihi'\n",
    "             }\n",
    "            )\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not okay\n",
    "darr = xr.DataArray(arr, \n",
    "             dims=['time', 'state'],\n",
    "             coords={\n",
    "                 'time': pd.date_range('2019-05-05', periods=3),\n",
    "                 'state': ['LA', 'SF'],\n",
    "                 'coord3': [0.01,1] # doesn't work because the value is an iterable \n",
    "             }\n",
    "            )\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is okay\n",
    "darr = xr.DataArray(arr, \n",
    "             dims=['time', 'state'],\n",
    "             coords={\n",
    "                 'time': pd.date_range('2019-05-05', periods=3),\n",
    "                 'state': ['LA', 'SF'],\n",
    "                 'coord3': ('time', [1,2,3]) # this works because 'time' is one of the dimensions\n",
    "                 #but fails if the length of the iterable doesn't match 'time's length, eg. [1,2,3,4]. Try it.\n",
    "             }\n",
    "            )\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is okay\n",
    "darr = xr.DataArray(arr, \n",
    "             dims=['time', 'state'],\n",
    "             coords={\n",
    "                 'time': pd.date_range('2019-05-05', periods=3),\n",
    "                 'state': ['LA', 'SF'],\n",
    "                 'coord3': ( ('time', 'state'), np.random.randn(6).reshape(3,2)) \n",
    "                 # okay because 'time' and 'state' are dimension names\n",
    "             }\n",
    "            )\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xr.DataArray` constructor from `pd.DataFrame`\n",
    "Precedant of propagating DataArray properties at construction time\n",
    "    - args to the `xr.DataArray` constructor\n",
    "    - non-specified arguments will be filled in from the `pandas` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr, columns=['LA', 'SF'], index=pd.date_range('2020-01-01', periods=3))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = xr.DataArray(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `df`'s index is set to the first dimension (which is named `dim_0` by default)'s coordinate, and `df`'s column names to the coordinate of the second dimension (`dim_1`).\n",
    "\n",
    "Let's try providing dimension names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = xr.DataArray(df, dims=['time', 'state'])\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the input `pd.DataFrame` instance has default index and column names?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = xr.DataArray(df)\n",
    "print(darr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same rule applies. That is, we use the input `df`'s index and columnnames to fill in non-specified filed for the new xr.DataArray object.\n",
    "\n",
    "Let's see if specifying the coordinates correctly take a precedance over the input `df`'s index and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = xr.DataArray(df,\n",
    "                    coords=[('time', pd.date_range('2021-01-01',periods=3)),\n",
    "                            ('state', ['LA', 'SF'])],\n",
    "                    #dims=['time', 'state'] # optional, as it's redundant\n",
    "                   )\n",
    "print(darr)\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the coordinates are set from the direct input arguments to `xr.DataArray` constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xr.DataArray.rename` method\n",
    "- returns a **new** xr.DataArray with the same (**NOT** a copied version of) data and modification on the properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_darr = darr.rename(state='us_state')\n",
    "print(new_darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(darr is new_darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see that the underlying data is copied as well\n",
    "print(darr.values is new_darr.values) # same as print(id(darr.values) == id(new_darr.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprise?! Is this really true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id(darr.values) == id(new_darr.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if changes in one array is reflected on the `renamed` DataArray's underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(darr.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr.values[0,0] = -100\n",
    "nprint(darr.values)\n",
    "nprint(new_darr.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. This is worthwhile to remember. \n",
    "\n",
    "> xr.DataArray.rename() will return a **new** instance with properties changed (eg. dimension names, coordinate values),\n",
    "but the new instance will have to the **same** handle to the original dataarray's `values`(ie. the underlying data)!!\n",
    "\n",
    "This means, changing the underlying data in one instance is directly reflected on the other instance. Nice in that the data is copied, but if we truely want a new instance, we need to figure out what's the right way to deep copy the underlying data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray's Dataset class\n",
    "Keys:\n",
    "- a variable is either `data_variable` (`data_var`) or `coordinate_variable`(`coords`)\n",
    "\n",
    "    For example, in the diagram below, `temperature` and `precipitation` are `data variable` and all other arrays are `coordinate variables`\n",
    "    <img src=\"../assets/xr_dataset_structure.png\" alt=\"xr_dataset\" width=\"500\"/>\n",
    "\n",
    "\n",
    "- multi-dimensional equivalent of a pd.Datafrmae + labelled axes\n",
    "- a dict-link container of labelled arrays (ie.xr.DataArray objects) with *aligned* dimensions\n",
    "- designed as an in-memory representation of the data model from the netCDF file format\n",
    "\n",
    "4 main properties of a Dataset object\n",
    "- dims: a dictionary mapping from dimension names to the fixed length of each dimension, eg: `{'dim0': 4, 'dim1': 3}`\n",
    "- data_vars: a dict-link container of DataArrays corresponding to variables\n",
    "- coords: a dict-link contain of DataArrays intended to label points used in `data_vars`\n",
    "- attrs: OrderedDict to hold arbitrary metadata\n",
    "\n",
    "- (xarray) `data_var` : `coord` = 'vdims' : 'kdims' (holoviews)\n",
    "- How to decide whether a variable belongs to `data_vars` or `coords`\"\n",
    "    - coordinates indicate constant/fixed/independed quantities \n",
    "    - varying/measured/dependednt quantities belongs to data\n",
    "- recall `coords.keys()` is a superset of `dims`\n",
    "\n",
    "<img src=\"../assets/create_dataset.png\" alt=\"create_dataset\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 70+10*np.random.randn(2,3,4)\n",
    "precip = 5+2*np.random.randn(2,3,4)\n",
    "lon = [[-99.81, -99.44, -99.23], \n",
    "       [-99.79, -99.34, -99.12]]\n",
    "lat = [[42.24, 42.21, 42.19],\n",
    "       [42.63, 42.59, 42.44]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data_vars = {\n",
    "    'temperature': xr.DataArray(data=temp,\n",
    "                                coords = [('x', [x_tick1, x_tick2]),\n",
    "                                          ('y', [y_tick1, y_tick2, y_tick3]),\n",
    "                                          ('t', [t_tick1, t_tick3, t_tick3, t_tick4])],\n",
    "                                dims = ['x','y','time'], # optional as it's redundant\n",
    "                                attrs = temp_metadata,\n",
    "                                name = temp_name\n",
    "                               ),\n",
    "    'precipitation': xr.DataArray(data = precip,\n",
    "                                  coords = [('x', [x_tick1, x_tick2]),\n",
    "                                          ('y', [y_tick1, y_tick2, y_tick3]),\n",
    "                                          ('time', [t_tick1, t_tick3, t_tick3, t_tick4])],\n",
    "                                  dims = ['x','y','time'], # optional as it's redundant\n",
    "                                 ),\n",
    "}\n",
    "```\n",
    "\n",
    "Note that we don't really know what to use to tickmark values for `x` and `y` coordinates. These are very general coordinates, to indicate the general two dimensional space, and no semantics attached. So, we use the second syntax (which only requires a list of dimension names ('x', 'y', 't') and the underlying data for the data_variable) to construct each data variable:\n",
    "\n",
    "```python\n",
    "    {\"varname\": (`dims`, `underlying_data`),\n",
    "    \"varname2\": (`dims`, `underlying_data`)}\n",
    "    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vars = {\n",
    "    'temperature': (['x','y','time'], temp),\n",
    "    'percipitation': (['x','y','time'], precip),\n",
    "}                             \n",
    "coord_vars = {\n",
    "    'lon': (['x','y'], lon),\n",
    "    'lat': (['x','y'], lat),\n",
    "    \n",
    "    # this is the last case (for the general coordinate variables, ie. x,y,t in our case\n",
    "#     'x': [val1, val2] <-- what to put in..? whatever is, not very meaningful\n",
    "#     'y': [ycoord1, ycoord2] <-- what to put in...? so we don't explicitly express these two\n",
    "    'time': pd.date_range('2019-05-28', periods=4),\n",
    "    'reference_time': pd.Timestamp('2019-05-27')\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    data_vars=data_vars,\n",
    "                \n",
    "    #coords should've named coord_vars, in my opinion\n",
    "    coords = coord_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty interesting. This is well-connected to the ideas behind holoviews `kdims` and `vdims`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create `holoviews.Dataset` from `xarray.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "- Pangeo architecture: [slides](https://is.gd/t9Rtqn)\n",
    "    - Bring computation to the data (big data)\n",
    "    - Uses `xarray`  which is supported by `Dask` in the backend\n",
    "- Great tutorial on how to use OPeNDAP server with GES DISC (NASA's open data portal)\n",
    "    - [link](https://is.gd/V4RJMS)\n",
    "- xarray: read opendap data\n",
    "    - [doc](http://xarray.pydata.org/en/stable/io.html#opendap)\n",
    "    - use xarray.open_dataset() for password-protected Opendap files: [link](https://github.com/pydata/xarray/issues/1068)\n",
    "    <img src=\"./assets/xarray-opendap.jpg\" alt=\"xarray-opendap\" width=\"500\"/>\n",
    "- xarray general tutorials\n",
    "    - [liasa](http://pure.iiasa.ac.at/id/eprint/14952/1/xarray-tutorial-egu2017-answers.pdf)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml]",
   "language": "python",
   "name": "conda-env-earthml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
