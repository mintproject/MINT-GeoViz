{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# FLDAS Explorer Dashboard\n",
    "Modified: Jun 13, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import datetime as dt\n",
    "import numpy as np, scipy as sp, pandas as pd, geopandas as gpd\n",
    "import intake,param\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print \n",
    "\n",
    "import joblib\n",
    "import pdb\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import ipywidgets as iw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "import xarray.ufuncs as xu\n",
    "\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param, Tap, Selection1D, PointerXY, RangeXY\n",
    "from holoviews import streams\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews import tile_sources as gvts\n",
    "\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'\n",
    "\n",
    "import panel as pn\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# SP_ROOT = Path.home()/'Playground/Semantic_Road/'\n",
    "# SP_UTILS = SP_ROOT/'scripts'\n",
    "\n",
    "# # Add the utils directorys to the search path\n",
    "CURR_UTILS = Path('../utils').absolute()\n",
    "\n",
    "DIRS2ADD = [CURR_UTILS]#, SP_UTILS]\n",
    "for UTILS_DIR in DIRS2ADD:\n",
    "    assert UTILS_DIR.exists()\n",
    "    if str(UTILS_DIR) not in sys.path:\n",
    "        sys.path.insert(0, str(UTILS_DIR))\n",
    "        print(f\"Added {str(UTILS_DIR)} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Grab registered bokeh renderer\n",
    "print(\"Currently available renderers: \", *hv.Store.renderers.keys())\n",
    "renderer = hv.renderer('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Path.ls = lambda x: [o.name for o in x.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, Point\n",
    "from geo_helpers import bounds2poly, crop_gdf_to_bounds, get_polys_at_lonlat\n",
    "from utils import nprint\n",
    "from river_helpers import load_river_csvs, get_basin_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Set default holoviews style options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%opts Image [colorbar=True, tools=['hover'], active_tools=['wheel_zoom']] Curve [tools=['hover']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "H,W = 800,1000\n",
    "CURVE_H, CURVE_W = 400, W\n",
    "opts.defaults(\n",
    "    \n",
    "    opts.Image(active_tools=['wheel_zoom'], tools=['hover'], colorbar=True),\n",
    "    opts.Curve(active_tools=['wheel_zoom'], tools=['hover'], padding=0.1,\n",
    "              height=CURVE_H, width=CURVE_W),\n",
    "    opts.Scatter(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "    opts.HLine(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "\n",
    "    opts.RGB(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "    opts.Overlay(active_tools=['wheel_zoom']),\n",
    "    \n",
    "    opts.Points(active_tools=['wheel_zoom'], tools=['hover','tap']),\n",
    "    opts.Path(active_tools=['wheel_zoom'], tools=['hover']),\n",
    "\n",
    "    opts.Polygons(active_tools=['wheel_zoom'], tools=['hover','tap']),\n",
    "    opts.WMTS(height=H, width=W),\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Basemap tile\n",
    "We need to handle the projection from latlon to web mercator (which is what the hv.tiles expect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# basemap = gvts.EsriImagery\n",
    "# basemap\n",
    "wmts_url = 'https://maps.wikimedia.org/osm-intl/{Z}/{X}/{Y}@2x.png'\n",
    "\n",
    "# basemap = gv.tile_sources.EsriImagery\n",
    "# basemap = gv.tile_sources.EsriUSATopo\n",
    "# basemap = gv.tile_sources.StamenTerrain\n",
    "topomap = gv.tile_sources.EsriNatGeo\n",
    "labelmap = gv.tile_sources.StamenLabels \n",
    "basemap = topomap #* labelmap\n",
    "\n",
    "# river = gv.feature.rivers\n",
    "# boarders = gv.Feature(cf.BORDERS)\n",
    "# base = basemap * boarders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    " 1. River measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_root = Path.home()/'data/mint'\n",
    "data_dir = data_root/'river'\n",
    "data = load_river_csvs(data_dir)\n",
    "data['geometry'] = gpd.points_from_xy(data.Longitude, data.Latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# nprint(len(data), data.head(), data.sample(10))\n",
    "c = 0\n",
    "for coord, g in data.groupby( ['Latitude', 'Longitude'] ):\n",
    "    if c >= 5:\n",
    "        break\n",
    "    print(coord, len(g))\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gvd = gv.Dataset(data, kdims=['Latitude', 'Longitude', 'Time'], vdims=['River_Width', 'River_Depth'])\n",
    "dmap = gvd.to(gv.Points, kdims=['Longitude', 'Latitude'], vdims=['River_Width', 'River_Depth'], \n",
    "             dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dmap.opts(color='River_Width', size='River_Width', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Get unique points: With Avg. Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "points = []\n",
    "lats, lons = [], []\n",
    "avg_ws = []\n",
    "for (lat,lon), g in data.groupby(['Latitude', 'Longitude']):\n",
    "    points.append(Point(lon, lat))\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    avg_ws.append(g.River_Width.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_avg = pd.DataFrame({'geometry': points,\n",
    "                           'Longitude': lons,\n",
    "                           'Latitude': lats,\n",
    "                           'River_Width_Avg': avg_ws})\n",
    "df_avg.head()\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gv_avg = gv.Points(df_avg, \n",
    "                   ['Longitude', 'Latitude'], \n",
    "                   'River_Width_Avg').opts(\n",
    "    color=dim('River_Width_Avg').norm(), \n",
    "    size=dim('River_Width_Avg').norm()*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_gv_avg(scale):\n",
    "    gv_avg = gv.Points(df_avg, \n",
    "                       ['Longitude', 'Latitude'], \n",
    "                       'River_Width_Avg')\n",
    "    return gv_avg.opts(color=dim('River_Width_Avg').norm(), \n",
    "                       size=dim('River_Width_Avg').norm()*scale)\n",
    "\n",
    "# parameterized class as a strem\n",
    "class Scale(param.Parameterized):\n",
    "    scale = param.Number(default=15, bounds=(10,30))\n",
    "    \n",
    "# Add flexibility to set the size of points\n",
    "scale = Scale()\n",
    "scale_stream = streams.Params(scale)\n",
    "dmap_gv_avg = hv.DynamicMap(get_gv_avg, \n",
    "                            streams=[scale_stream])\n",
    "# dmap_gv_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "2. Basins data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "basin_dir = data_root/'hybas_world_lev05_v1c'; assert basin_dir.exists()\n",
    "bounds = (32.95418, 3.42206, 47.78942, 14.95943)#todo\n",
    "\n",
    "gdf_basins = crop_gdf_to_bounds( gpd.read_file(basin_dir)[['HYBAS_ID', 'geometry']],\n",
    "                                bounds,\n",
    "                                remove_empty=True).reset_index().drop('index', axis=1)\n",
    "gdf_basins['HYBAS_ID']=gdf_basins.HYBAS_ID.astype(str)\n",
    "print(len(gdf_basins))\n",
    "# gdf_basins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gv_basins = gv.Polygons(gdf_basins, vdims=['HYBAS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %%opts WMTS [height=H, width=W] Polygons(alpha=0.5)\n",
    "# basemap * gv_basins * dmap * dmap_gv_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "3. Assign basin_id to points in river measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## GeoPandas from river pandas dataframe\n",
    "bids = []\n",
    "c = 0\n",
    "for lon, lat in zip(data.Longitude, data.Latitude):\n",
    "    bid = get_basin_id(gdf_basins, lon,lat)\n",
    "    bids.append(bid)\n",
    "#     if c%30==0: print(lon, lat, bid)\n",
    "    c += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data['HYBAS_ID'] = bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Geopadnas river measurement data\n",
    "gdf_data = gpd.GeoDataFrame(data)\n",
    "gdf_data.crs = {'init': 'epsg:4326'}\n",
    "# gdf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Add LatLon Tab selector stream\n",
    "- Fetch the lat/lon of the mouse click position on the basemap\n",
    "\n",
    "    1. Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def select_data_at_lonlat(data, lon, lat):\n",
    "    \"\"\"\n",
    "    data: dataFrame or GeoDataFrame\n",
    "    lat: float\n",
    "    lon: float\n",
    "    \"\"\"\n",
    "    return data[np.isclose(data.Longitude, lon) & np.isclose(data.Latitude, lat)]\n",
    "\n",
    "def tseries_from_lonlat(data, lon, lat):\n",
    "    df = select_data_at_latlon(data, lon, lat)\n",
    "    curve_w = hv.Curve(df, 'Time', 'River_Width', label='width')\n",
    "    curve_d = hv.Curve(df, 'Time', 'River_Depth', label='depth')\n",
    "    return curve_w * curve_d \n",
    "\n",
    "def tseries_from_index(data, \n",
    "                       index_src, \n",
    "                       index):\n",
    "    if len(index) < 1:\n",
    "        return hv.Curve([])\n",
    "    elif len(index) > 1:\n",
    "        print('Warning: multiple points were selected. Only care for the first point')\n",
    "        index = index[:1]\n",
    "              \n",
    "    lon,lat = index_src.iloc[index].Longitude.item(),index_src.iloc[index].Latitude.item()\n",
    "    print(lon, type(lon),lat, type(lat))\n",
    "    df = select_data_at_lonlat(data, lon, lat)\n",
    "    curve_w = hv.Curve(df, 'Time', 'River_Width', label='width')\n",
    "    curve_d = hv.Curve(df, 'Time', 'River_Depth', label='depth')\n",
    "    return curve_w * curve_d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "    2. Register streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# stream_xy = PointerXY(name='lonlat', \n",
    "#                     x=34., y=9., source=gv_basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stream_tab = Selection1D(name='tab', source=gv_avg, index=[0])\n",
    "dmap_tab = hv.DynamicMap(lambda index: hv.Div(f'point index:  {index}'),\n",
    "                        streams=[stream_tab])\n",
    "dmap_tseries = hv.DynamicMap(lambda index: tseries_from_index(data, df_avg, index),\n",
    "                             streams=[stream_tab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stream_btab = Selection1D(name='btap', source=gv_basins, index=[0])\n",
    "debug_btab = hv.DynamicMap(lambda index: hv.Div(f'basin index:  {index}'),\n",
    "                        streams=[stream_btab])\n",
    "# gv_basins + debug_btab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "min_val = np.min(data[['River_Width', 'River_Depth']].min().to_list())\n",
    "max_val = np.max(data[['River_Width', 'River_Depth']].max().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#overlay\n",
    "#cmap for points:  plt.cm.gist_earth, plasma, inferno, fire, visidis\n",
    "scale.sacle=40\n",
    "\n",
    "app = (\n",
    "    basemap \n",
    "    * gv_avg.opts(cmap='plasma') #* dmap_gv_avg \n",
    "    * gv_basins.opts(alpha=0.1)\n",
    "    + dmap_tseries.opts(\n",
    "     opts.Curve(framewise=True, \n",
    "                show_grid=True, \n",
    "                ylim=(min_val,max_val)\n",
    "               )\n",
    " )\n",
    ").cols(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pane = pn.panel(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pane.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
